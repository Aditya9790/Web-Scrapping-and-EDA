{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image Labelling.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP0uLywJ2xb/KsvoMDdBtcf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aditya9790/Web-Scrapping-and-EDA/blob/main/Image_Labelling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQ-ilOyCuQhm",
        "outputId": "8a0414a0-aa2b-4990-f31e-bc373bf82c97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import os\n",
        "import requests"
      ],
      "metadata": {
        "id": "0ij0Ufth2jor"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_keyword = input(\"Enter keyword : \")\n",
        "num_images = int(input(\"Enter number of images to be downloaded : \"))\n",
        "# Query which will be passed to google\n",
        "query = ' '.join(image_keyword.split())\n",
        "\n",
        "# From this url we are going to fetch images\n",
        "url = 'https://www.google.com/search?q=' + query + '&tbm=isch&ved=2ahUKEwiN7rPF2qf1AhWSR3wKHR-GBDsQ2-cCegQIABAA&oq=blue+car&gs_lcp=CgNpbWcQAzIHCCMQ7wMQJzIICAAQgAQQsQMyBQgAEIAEMgUIABCABDIFCAAQgAQyBQgAEIAEMgUIABCABDIFCAAQgAQyBQgAEIAEMgUIABCABFCGC1iGC2DYD2gAcAB4AIABdYgB4gGSAQMwLjKYAQCgAQGqAQtnd3Mtd2l6LWltZ8ABAQ&sclient=img&ei=o2zcYc2QC5KP8QOfjJLYAw&bih=609&biw=1280'\n",
        "print(url)\n",
        "folder_name = 'Google Images'\n",
        "\n",
        "# Here you can give the path of your local machine or your googlr drive acc to youe prefrence\n",
        "folder_path = '/content/drive/MyDrive/Colab Notebooks/Diploma/Tools in Data Science/' + folder_name\n",
        "\n",
        "# If folder named Google Path does not exist create one\n",
        "# if not os.path.exists('folder_path'):\n",
        "#     os.mkdir(folder_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XHqYFHe3F40",
        "outputId": "5d1e9b6a-1e15-44ff-d8e4-493f3a8f5678"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter keyword : dog\n",
            "Enter number of images to be downloaded : 10\n",
            "https://www.google.com/search?q=dog&tbm=isch&ved=2ahUKEwiN7rPF2qf1AhWSR3wKHR-GBDsQ2-cCegQIABAA&oq=blue+car&gs_lcp=CgNpbWcQAzIHCCMQ7wMQJzIICAAQgAQQsQMyBQgAEIAEMgUIABCABDIFCAAQgAQyBQgAEIAEMgUIABCABDIFCAAQgAQyBQgAEIAEMgUIABCABFCGC1iGC2DYD2gAcAB4AIABdYgB4gGSAQMwLjKYAQCgAQGqAQtnd3Mtd2l6LWltZ8ABAQ&sclient=img&ei=o2zcYc2QC5KP8QOfjJLYAw&bih=609&biw=1280\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# You can get u_agent just be entering my agent on chrome search bar\n",
        "# This is needed for the webpage to verify\n",
        "u_agent = {\n",
        "    'User-Agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.110 Safari/537.36',\n",
        "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
        "    'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3',\n",
        "    'Accept-Encoding': 'none',\n",
        "    'Accept-Language': 'en-US,en;q=0.8',\n",
        "    'Connection': 'keep-alive',\n",
        "}\n",
        "\n",
        "# A function that downloades the image that is scraped from google\n",
        "def download_image(url, num_images, u_agent, keyword_class):\n",
        "\n",
        "    # sends request to browser\n",
        "    response = requests.get(url, headers = u_agent)\n",
        "    html = response.text # convert html data to test mode\n",
        "    b_soup = BeautifulSoup(html, 'html.parser')\n",
        "    # find all the results that have img as keyword and are in class=keyword_class\n",
        "    results = b_soup.findAll('img', {'class': keyword_class}) \n",
        "\n",
        "    count = 0\n",
        "    image_link = [] # append all links of the keyword\n",
        "\n",
        "    # loop through the tags from each results and extract all the links\n",
        "    for tag in results:\n",
        "        try:\n",
        "            link = tag['data-src']\n",
        "            image_link.append(link)\n",
        "            count += 1\n",
        "            if count > num_images:\n",
        "                break\n",
        "        except KeyError:\n",
        "            continue\n",
        "    # the list will contain the links for insividual image\n",
        "    print(f'Found {num_images} links.')\n",
        "    print('Start Downloading...')\n",
        "\n",
        "    # now with the help of the links we will download the images\n",
        "    for i, link in enumerate(image_link):\n",
        "        # Open each image and save it\n",
        "        image = requests.get(link) # send request\n",
        "\n",
        "        # save image as jpg\n",
        "        image_name = folder_path + '/' + image_keyword + str(i) + '.jpg'\n",
        "\n",
        "        with open(image_name, 'wb') as f:\n",
        "            f.write(image.content) # write in image filr the image\n",
        "    print(f'Images are downloaded at : {folder_path}')\n",
        "    print(\"Finished Downloading\")\n",
        "\n",
        "keyword_class = 'rg_i Q4LuWd'\n",
        "download_image(url, num_images, u_agent, keyword_class)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y49aXoqMC7LG",
        "outputId": "be0fa23f-568d-4734-ce5d-34a3528d58a5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 10 links.\n",
            "Start Downloading...\n",
            "Images are downloaded at : /content/drive/MyDrive/Colab Notebooks/Diploma/Tools in Data Science/Google Images\n",
            "Finished Downloading\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "iH2_dQcFPemc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}